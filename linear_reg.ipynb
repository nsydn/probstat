{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_reg.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyODwta1eO7IUkXOk36MRGYF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nsydn/probstat/blob/master/linear_reg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD1ycu_T4Fa3"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfBf7og6-PCx"
      },
      "source": [
        "### The Boston Housing Dataset\n",
        "The Boston Housing Dataset includes data concerning housing in the towns of Boston, MA. The following describes the dataset columns:\n",
        "\n",
        "* CRIM: per capita crime rate by town\n",
        "* RM: average number of rooms per unit\n",
        "* AGE: proportion of units built before 1940\n",
        "* DIS: weighted distances to five Boston employment centres\n",
        "* PTRATIO: pupil-teacher ratio by town\n",
        "* LSTAT: proportion (\\%) of low-educated population\n",
        "* MEDV: median value of houses (in \\$1000 units)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKDlJL325xuu"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U9tz3w67moW"
      },
      "source": [
        "from pandas import read_csv\n",
        "column_names = ['CRIM', 'RM', 'AGE', 'DIS', 'PTRATIO', 'LSTAT', 'MEDV']\n",
        "data = read_csv('housing_clean.csv', header=None, names=column_names)\n",
        "print(data.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-F-XlDX86Lr"
      },
      "source": [
        "print(np.shape(data))\n",
        "print(data.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI5cM_155TmJ"
      },
      "source": [
        "# visualize the relationship between the features and the response using scatterplots\n",
        "fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
        "axs[0].scatter(data.LSTAT, data.MEDV, color='blue'); axs[0].set_xlabel('LSTAT'); axs[0].set_ylabel('MEDV')\n",
        "axs[1].scatter(data.RM, data.MEDV, color='orange'); axs[1].set_xlabel('RM');\n",
        "axs[2].scatter(data.DIS, data.MEDV, color='green'); axs[2].set_xlabel('DIS'); \n",
        "axs[3].scatter(data.AGE, data.MEDV, color='red'); axs[3].set_xlabel('AGE'); \n",
        "# axs[4].scatter(data.CRIM, data.MEDV, color='blue'); axs[4].set_xlabel('CRIM'); "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvfrkbLmKIPD"
      },
      "source": [
        "### Hypothesis\n",
        "We'd like to propose the following hypothesis:\n",
        "\n",
        "*   $H_0$: $\\beta_1=\\beta_2=\\dots=\\beta_k=0$ (There is no significant relation between $X$ variables and $Y$.)\n",
        "*   $H_1$: $\\beta_j\\neq 0$ at least for one $j\\in\\{1,\\dots,k\\}$ (There is significant relation between at least one $X$ variable and $Y$.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-cb9AQZMxWR"
      },
      "source": [
        "### Simple Linear Regression\n",
        "\n",
        "Simple linear regression is an approach for predicting a quantitative **response** using a **one or more features** (or \"regressors\" or \"predictors\" or \"input variables\" or \"independent variables\"). It takes the following form:\n",
        "\n",
        "$y = \\beta_0 + \\beta_1x_1 + \\dots + \\beta_nx_n + \\epsilon$\n",
        "\n",
        "- $y$ is the response\n",
        "- $x_1,\\dots,x_n$ are features\n",
        "- $\\beta_0$ is the **population** intercept coefficient\n",
        "- $\\beta_1,\\dots,\\beta_n$ are the *population* slope coefficients for $x_1,\\dots,x_n$\n",
        "- $\\epsilon$ is the **population** error/residual/innovation term\n",
        "\n",
        "To be able use our model, we must **estimate** the values of these coefficients based on available data (**model training**). And once we've estimated these coefficients, we can use the model to **predict** $y$ values for items that are not in our sample (**model test**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAwag8_vNAWC"
      },
      "source": [
        "### Estimating the Model Coefficients (Training the Model)\n",
        "\n",
        "Now, assume we have a data set of $N$ observations. Model coefficients are generally estimated using the ordinary **Least Squares Method**, which means we are estimating the regression line that minimizes the **sum of squared errors** and therefore maximizes the $R^2$: $$SSE=\\sum_{i=1}^N (y_i-\\hat{y})^2=\\sum_{i=1}^N e_i^2\\quad R^2=1-\\frac{SSE}{TSS}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIHgh4JQNZNe"
      },
      "source": [
        "* **`linregress`**: Python `scipy`'s `linregress` function can only be used for **single-variable** regressions. Alternatively, we can use `statsmodels` to estimate the model coefficients for the house price data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbwAmABUNpgA"
      },
      "source": [
        "# Run a single-variable regression\n",
        "x=data.RM; y=data.MEDV\n",
        "from scipy import stats\n",
        "b1,b0,rho,p,se = stats.linregress(x,y)\n",
        "print(' Intercept (b0): %.4f\\n Slope (b1): %.4f\\n P-value: %.4f\\n R-squared: %.4f' % (b0,b1,p,rho**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76F0111wQZqQ"
      },
      "source": [
        "# Plot the regression vs. actual\n",
        "plt.plot(x, y, 'o', label='actual')\n",
        "plt.plot(x, b0 + b1*x, 'r', label='fitted')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsLaSV4f8Wuk"
      },
      "source": [
        "* **`statsmodels`**: Getting a detailed regression report is not easy in `stats.linregress`. Instead, we can use `statsmodels` which also allows for **multi-variable** regressions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImaE8q4wNMYU"
      },
      "source": [
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Define and fit a regression model\n",
        "model = smf.ols(formula='MEDV ~ RM', data=data)\n",
        "linreg = model.fit()\n",
        "\n",
        "# Print the model coefficients or a summary table\n",
        "print(linreg.params)\n",
        "print(linreg.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raDgbDYwwQ5C"
      },
      "source": [
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Define and fit a regression model\n",
        "model = smf.ols(formula='MEDV ~ LSTAT + RM + DIS + AGE', data=data)\n",
        "linreg = model.fit()\n",
        "\n",
        "# Print the model coefficients or a summary table\n",
        "print(linreg.params)\n",
        "print(linreg.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-Q7xZ8AR1a6"
      },
      "source": [
        "### Interpreting the Model Coefficients\n",
        "\n",
        "How do we interpret the `LSTAT`, `RM`, `AGE` and `DIS` coefficients ($b_1$, $b_2$, $b_3$ and $b_4$) estimated from our example?\n",
        "- A unit increase in the proportion of low-status population (`LSTAT`) is **associated with** a `0.4376` unit (in \\$1000) decrease in median value of houses (when other variables `RM`, `AGE`, `DIS` are kept constant).\n",
        "- A unit increase in the average number of rooms per house (`RM`) is **associated with** a `6.1846` unit (in \\$1000) increase in median value of houses (when other variables `LSTAT`, `AGE`, `DIS` are kept constant).\n",
        "- Similar interpretations for $b_3$ and $b_4$ ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CMgOuOaFvjw"
      },
      "source": [
        "It is good to recall few points:\n",
        "\n",
        "- $B_0$ and $B_1$ are estimators of population parameters $\\beta_0$ and $\\beta_1$\n",
        "- This means $B_0$ and $B_1$ have their own sampling distributions (It is Student's $t$ distribution.).\n",
        "- Coefficients $b_0$ and $b_1$ are realizations of $B_0$ and $B_1$ estimated from a certain sample\n",
        "- We can indeed use $b_0$ and $b_1$ to make inferences about $\\beta_0$ and $\\beta_1$ (e.g., build confidence intervals, carry out hypothesis tests, etc.)\n",
        "<!-- - But for this class, we will not *manually* calculate $t$ values or derive confidence intervals for $\\beta_0$ and $\\beta_1$. We'll only interpret outputs from `scipy`, `statsmodels` or `sklearn`. -->\n",
        "\n",
        "<!-- By default `statsmodels` calculates two-sided 95% confidence intervals for our model coefficients, but we can change it to any $\\alpha$ value we want. We can create 90% confidence intervals (which would be be more narrower) or 99% confidence intervals (which would be wider), or whatever intervals we like. -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioQliVZ_QBBk"
      },
      "source": [
        "* Again, remember that $R^2$ should not be used for comparing models with different number of regressors (because adding new regressors lead to artificially higher values of $R^2$ and causes **overfitting** and this is true even if they are unrelated to the response $Y$). \n",
        "<!-- Is that a \"good\" R-squared value? It's hard to say. The threshold for a good R-squared value depends widely on the domain.  -->\n",
        "<!-- Therefore, it's most useful as a tool for **comparing different models**. -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh6Kc9AVQIN1"
      },
      "source": [
        "* **R-squared will always increase as you add more features to the model**, even if they are unrelated to the response. Thus, selecting the model with the highest R-squared is not a reliable approach for choosing the best linear model.\n",
        "\n",
        "* There is alternative to R-squared called **adjusted R-squared** that penalizes model complexity to control for overfitting (Adjusted $R^2$ is reported in the regression summary table obtained using `reg_line.summary()` command.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFD8J5HBEtbz"
      },
      "source": [
        "import scipy.stats as stats\n",
        "#plt.scatter(reg_line.resid,)\n",
        "qq = stats.probplot(reg_line.resid,dist=stats.norm,plot=plt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYfDRM8EwCot"
      },
      "source": [
        "### Using the Model for Prediction\n",
        "\n",
        "Assume that the median value for a new town with $\\{x_1,x_2,x_3,x_4\\}=\\{20,7,6,50\\}$ will be predicted. \n",
        "\n",
        "$$\\hat{y} = b_0 + b_1x_1 + b_2x_2 + b_3x_3 + b_4x_4$$\n",
        "<!-- $$\\hat{y} = -5.9274 - 0.4376(20) + 6.1846(7) - 0.0493(6) - 0.4698(50)$$ -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMK-aieGREyo"
      },
      "source": [
        "# First, generate a dataframe for the new observation\n",
        "x_new = pd.DataFrame({'LSTAT': [20], 'RM': [5], 'DIS': [6], 'AGE': [50]})\n",
        "print(x_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAORzzSrUUQ5"
      },
      "source": [
        "# Use x_new to predict y\n",
        "y_hat = linreg.predict(x_new)\n",
        "print(y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofus1T0HYHMc"
      },
      "source": [
        "Thus, we predict a `MEDV` of $\\hat{y}=10.96$ (in \\$1000 units) for the new town. If we knew that $y=10.50$ for that town, then our prediction error would be $e=0.46$ units for that specific observation. "
      ]
    }
  ]
}